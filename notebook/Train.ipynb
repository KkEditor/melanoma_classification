{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from efficientnet.tfkeras import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "from tensorflow_addons.optimizers import SWA\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed():\n",
    "    random.seed(2021)\n",
    "    tf.random.set_seed(2020)\n",
    "    np.random.seed(2019)\n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HairAugmentation(DualTransform):\n",
    "    \"\"\"\n",
    "    Impose an image of a hair to the target image\n",
    "\n",
    "    Args:\n",
    "        hairs (int): maximum number of hairs to impose\n",
    "        hairs_folder (str): path to the folder with hairs images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hairs, hairs_data, always_apply=False, p=0.5):\n",
    "        super(HairAugmentation, self).__init__(always_apply, p)\n",
    "        self.hairs = hairs\n",
    "        self.hairs_data = hairs_data\n",
    "\n",
    "    def apply(self, image, n_hairs, **params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to draw hairs on.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with drawn hairs.\n",
    "        \"\"\"    \n",
    "        if not n_hairs:\n",
    "            return image\n",
    "        \n",
    "        height, width, _ = image.shape  # target image width and height\n",
    "        \n",
    "        for _ in range(n_hairs):\n",
    "            idx = np.random.randint(0, len(self.hairs_data))\n",
    "            hair = self.hairs_data[idx]\n",
    "            hair = cv2.flip(hair, np.random.choice([-1, 0, 1]))\n",
    "            hair = cv2.rotate(hair, np.random.choice([0, 1, 2]))\n",
    "\n",
    "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "            roi_ho = np.random.randint(0, image.shape[0] - hair.shape[0])\n",
    "            roi_wo = np.random.randint(0, image.shape[1] - hair.shape[1])\n",
    "            roi = image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
    "\n",
    "            # Creating a mask and inverse mask\n",
    "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "            # Now black-out the area of hair in ROI\n",
    "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "            # Take only region of hair from hair image.\n",
    "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
    "\n",
    "            # Put hair in ROI and modify the target image\n",
    "            dst = cv2.add(img_bg, hair_fg)\n",
    "\n",
    "            image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        n_hairs = np.random.randint(0, self.hairs)\n",
    "        return {'n_hairs': n_hairs }\n",
    "    \n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "    \n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('hairs', 'hairs_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "prev_img_size = None\n",
    "BATCH_SIZE = 64\n",
    "SPLITS = 5\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "TRAIN_IMAGE_PATH = '../data/train_256'\n",
    "\n",
    "ORIGINAL_TRAIN_DF = pd.read_csv('../data/cleaned_train.csv')\n",
    "EXTERNAL_TRAIN_DF = pd.read_csv('../data/external_train.csv')\n",
    "\n",
    "model_name = 'seresnet18'\n",
    "PHI = 0\n",
    "initial_lr = 1e-4\n",
    "min_lr = 1e-5\n",
    "\n",
    "# Prepare hairs data for Hair Augmentation\n",
    "hairs_data = []\n",
    "for file in os.listdir('../data/hairs'):\n",
    "    img = cv2.imread(f'../data/hairs/{file}')\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.resize(img, (w // 4, h // 4), cv2.INTER_AREA)\n",
    "    hairs_data.append(img)\n",
    "\n",
    "train_aug = A.Compose([\n",
    "#                 HairAugmentation(hairs=5, hairs_data=hairs_data),\n",
    "                A.Flip(),\n",
    "                A.ShiftScaleRotate(),\n",
    "                A.RandomBrightnessContrast(),\n",
    "                A.Cutout(num_holes=1, max_h_size=IMG_SIZE // 2, max_w_size=IMG_SIZE // 2)\n",
    "            ])\n",
    "test_aug = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Data Generator\n",
    "'''\n",
    "class Datagen(Sequence):\n",
    "    def __init__(self, list_ids, targets, batch_size, image_dir, generator=None, mode='training'):\n",
    "        self.list_ids = list_ids\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dir = image_dir\n",
    "        self.generator = generator\n",
    "        self.indices = np.arange(self.list_ids.shape[0])\n",
    "        self.mode = mode\n",
    "        \n",
    "    def preprocessing_image(self, image):\n",
    "        image = image.astype('float32') / 255.\n",
    "        return image\n",
    "        \n",
    "    def read_image(self, image_id):\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR) \n",
    "        return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_ids) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index + 1)*self.batch_size]\n",
    "        image_ids = self.list_ids[indices]\n",
    "        y = self.targets[indices]\n",
    "        X = np.empty((len(image_ids), IMG_SIZE, IMG_SIZE, 3), dtype='float32')\n",
    "        for i in range(len(image_ids)):\n",
    "            image = self.read_image(image_ids[i])\n",
    "            if self.generator is not None:\n",
    "                image = self.generator(image=image)['image']\n",
    "            image = self.preprocessing_image(image)\n",
    "            X[i] = image\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode == 'training':\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Model\n",
    "'''\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.75):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def build_model(fold=None, prev_img_size=None):\n",
    "    M = 0\n",
    "    EFFNET_MODEL = [EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3]\n",
    "    if 'efficientnet' in model_name:\n",
    "        M = EFFNET_MODEL[PHI]\n",
    "    else:\n",
    "        M, _ = Classifiers.get(model_name)\n",
    "    base_model = M(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "    model = Model(inputs=[base_model.input], outputs=[out])\n",
    "    if prev_img_size is not None:\n",
    "        model.load_weights(f'../data/model_checkpoint/{model_name}/{model_name}_{prev_img_size}_fold_{fold}.h5')\n",
    "    opt = keras.optimizers.Adam(lr=initial_lr)\n",
    "    opt = SWA(opt)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=focal_loss(),\n",
    "                  metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Callback\n",
    "'''\n",
    "def scheduler(epoch):\n",
    "    return min_lr + (initial_lr - min_lr) * (1 + np.cos(np.pi * (epoch % EPOCHS) / EPOCHS)) / 2\n",
    "\n",
    "class Evaluate(keras.callbacks.Callback):\n",
    "    def __init__(self, fold, train_gen, valid_gen, model_checkpoint):\n",
    "        self.fold = fold\n",
    "        self.train_gen = train_gen\n",
    "        self.valid_gen = valid_gen\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.best_score = float('-inf')\n",
    "    \n",
    "    def compute_auc(self, y_true, y_pred):\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.train_gen.on_epoch_end()\n",
    "        _, auc = self.model.evaluate_generator(self.valid_gen, verbose=1)\n",
    "        new_lr = scheduler(epoch + 1)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "        print(\"Set LR to {}\".format(new_lr))\n",
    "        print(\"AUC: {}\".format(auc))\n",
    "        if auc > self.best_score:\n",
    "            print(f\"AUC improved from {self.best_score} to {auc}\")\n",
    "            self.best_score = auc\n",
    "            self.model.save_weights(f'{self.model_checkpoint}/{model_name}_{IMG_SIZE}_fold_{self.fold}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_image_ids = np.asarray(EXTERNAL_TRAIN_DF['image_name'])\n",
    "external_targets = np.asarray(EXTERNAL_TRAIN_DF['target'], dtype='float32')\n",
    "\n",
    "image_ids = np.asarray(ORIGINAL_TRAIN_DF['image_name'])\n",
    "targets = np.asarray(ORIGINAL_TRAIN_DF['target'], dtype='float32')\n",
    "\n",
    "image_ids = np.concatenate([image_ids, external_image_ids])\n",
    "targets = np.concatenate([targets, external_targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4953.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Fold 0*************\n",
      "WARNING:tensorflow:From <ipython-input-11-e7877a954cd2>:31: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "  2/715 [..............................] - ETA: 1:11 - loss: 0.0606 - auc: 0.5350WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0760s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n",
      "715/715 [==============================] - ETA: 0s - loss: 0.0325 - auc: 0.8311WARNING:tensorflow:From <ipython-input-9-ea84bc0c07a3>:20: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0880 - auc: 0.5186\n",
      "Set LR to 9.779754323328192e-05\n",
      "AUC: 0.5185584425926208\n",
      "AUC improved from -inf to 0.5185584425926208\n",
      "715/715 [==============================] - 168s 235ms/step - loss: 0.0325 - auc: 0.8311\n",
      "Epoch 2/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0226 - auc: 0.9180\n",
      "Set LR to 9.140576474687264e-05\n",
      "AUC: 0.9179518818855286\n",
      "AUC improved from 0.5185584425926208 to 0.9179518818855286\n",
      "715/715 [==============================] - 169s 236ms/step - loss: 0.0210 - auc: 0.9286\n",
      "Epoch 3/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0296 - auc: 0.9126\n",
      "Set LR to 8.14503363531613e-05\n",
      "AUC: 0.9126163125038147\n",
      "715/715 [==============================] - 165s 231ms/step - loss: 0.0123 - auc: 0.9781\n",
      "Epoch 4/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0752 - auc: 0.9032\n",
      "Set LR to 6.890576474687264e-05\n",
      "AUC: 0.9031845927238464\n",
      "715/715 [==============================] - 165s 231ms/step - loss: 0.0058 - auc: 0.9955\n",
      "Epoch 5/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0396 - auc: 0.9113\n",
      "Set LR to 5.5e-05\n",
      "AUC: 0.911300778388977\n",
      "715/715 [==============================] - 166s 233ms/step - loss: 0.0025 - auc: 0.9994\n",
      "Epoch 6/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0557 - auc: 0.9201\n",
      "Set LR to 4.109423525312737e-05\n",
      "AUC: 0.9201125502586365\n",
      "AUC improved from 0.9179518818855286 to 0.9201125502586365\n",
      "715/715 [==============================] - 166s 232ms/step - loss: 0.0010 - auc: 0.9999\n",
      "Epoch 7/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0532 - auc: 0.9178\n",
      "Set LR to 2.8549663646838717e-05\n",
      "AUC: 0.9177612066268921\n",
      "715/715 [==============================] - 166s 232ms/step - loss: 5.6415e-04 - auc: 1.0000\n",
      "Epoch 8/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0602 - auc: 0.9230\n",
      "Set LR to 1.859423525312737e-05\n",
      "AUC: 0.9229914546012878\n",
      "AUC improved from 0.9201125502586365 to 0.9229914546012878\n",
      "715/715 [==============================] - 165s 231ms/step - loss: 2.9715e-04 - auc: 1.0000\n",
      "Epoch 9/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0657 - auc: 0.9202\n",
      "Set LR to 1.2202456766718093e-05\n",
      "AUC: 0.9201963543891907\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 1.4705e-04 - auc: 1.0000\n",
      "Epoch 10/10\n",
      "881/881 [==============================] - 17s 20ms/step - loss: 0.0583 - auc: 0.9244\n",
      "Set LR to 0.0001\n",
      "AUC: 0.9243723750114441\n",
      "AUC improved from 0.9229914546012878 to 0.9243723750114441\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 8.7257e-05 - auc: 1.0000\n",
      "***********Fold 1*************\n",
      "Epoch 1/10\n",
      "  2/715 [..............................] - ETA: 1:12 - loss: 0.0558 - auc: 0.2460WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0770s vs `on_train_batch_end` time: 0.1250s). Check your callbacks.\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0810 - auc: 0.4973\n",
      "Set LR to 9.779754323328192e-05\n",
      "AUC: 0.49734318256378174\n",
      "AUC improved from -inf to 0.49734318256378174\n",
      "715/715 [==============================] - 168s 235ms/step - loss: 0.0323 - auc: 0.8316\n",
      "Epoch 2/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0259 - auc: 0.9095\n",
      "Set LR to 9.140576474687264e-05\n",
      "AUC: 0.9095335602760315\n",
      "AUC improved from 0.49734318256378174 to 0.9095335602760315\n",
      "715/715 [==============================] - 168s 235ms/step - loss: 0.0200 - auc: 0.9362\n",
      "Epoch 3/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0432 - auc: 0.9065\n",
      "Set LR to 8.14503363531613e-05\n",
      "AUC: 0.9064717292785645\n",
      "715/715 [==============================] - 168s 235ms/step - loss: 0.0107 - auc: 0.9835\n",
      "Epoch 4/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0326 - auc: 0.9064\n",
      "Set LR to 6.890576474687264e-05\n",
      "AUC: 0.9064171314239502\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 0.0046 - auc: 0.9974\n",
      "Epoch 5/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0537 - auc: 0.9069\n",
      "Set LR to 5.5e-05\n",
      "AUC: 0.9068615436553955\n",
      "715/715 [==============================] - 162s 227ms/step - loss: 0.0020 - auc: 0.9996\n",
      "Epoch 6/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0466 - auc: 0.9099\n",
      "Set LR to 4.109423525312737e-05\n",
      "AUC: 0.9098753333091736\n",
      "AUC improved from 0.9095335602760315 to 0.9098753333091736\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 8.7280e-04 - auc: 0.9999\n",
      "Epoch 7/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0645 - auc: 0.9062\n",
      "Set LR to 2.8549663646838717e-05\n",
      "AUC: 0.9061855673789978\n",
      "715/715 [==============================] - 167s 233ms/step - loss: 4.9430e-04 - auc: 1.0000\n",
      "Epoch 8/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0655 - auc: 0.9098\n",
      "Set LR to 1.859423525312737e-05\n",
      "AUC: 0.9098365306854248\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 1.8188e-04 - auc: 1.0000\n",
      "Epoch 9/10\n",
      "881/881 [==============================] - 18s 20ms/step - loss: 0.0674 - auc: 0.9072\n",
      "Set LR to 1.2202456766718093e-05\n",
      "AUC: 0.9072296619415283\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 1.0590e-04 - auc: 1.0000\n",
      "Epoch 10/10\n",
      "881/881 [==============================] - 18s 21ms/step - loss: 0.0675 - auc: 0.9073\n",
      "Set LR to 0.0001\n",
      "AUC: 0.9072842001914978\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 8.8956e-05 - auc: 1.0000\n",
      "***********Fold 2*************\n",
      "Epoch 1/10\n",
      "409/409 [==============================] - 18s 44ms/step - loss: 0.0879 - auc: 0.5103\n",
      "Set LR to 9.779754323328192e-05\n",
      "AUC: 0.5102588534355164\n",
      "AUC improved from -inf to 0.5102588534355164\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 0.0371 - auc: 0.8229\n",
      "Epoch 2/10\n",
      "409/409 [==============================] - 18s 44ms/step - loss: 0.0255 - auc: 0.9097\n",
      "Set LR to 9.140576474687264e-05\n",
      "AUC: 0.9097063541412354\n",
      "AUC improved from 0.5102588534355164 to 0.9097063541412354\n",
      "715/715 [==============================] - 165s 231ms/step - loss: 0.0202 - auc: 0.9348\n",
      "Epoch 3/10\n",
      "409/409 [==============================] - 18s 43ms/step - loss: 0.0251 - auc: 0.9121\n",
      "Set LR to 8.14503363531613e-05\n",
      "AUC: 0.9121029376983643\n",
      "AUC improved from 0.9097063541412354 to 0.9121029376983643\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 0.0124 - auc: 0.9770\n",
      "Epoch 4/10\n",
      "409/409 [==============================] - 18s 44ms/step - loss: 0.0344 - auc: 0.9069\n",
      "Set LR to 6.890576474687264e-05\n",
      "AUC: 0.906937837600708\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 0.0057 - auc: 0.9959\n",
      "Epoch 5/10\n",
      "409/409 [==============================] - 18s 43ms/step - loss: 0.0598 - auc: 0.9038\n",
      "Set LR to 5.5e-05\n",
      "AUC: 0.903829038143158\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 0.0022 - auc: 0.9996\n",
      "Epoch 6/10\n",
      "409/409 [==============================] - 18s 44ms/step - loss: 0.0498 - auc: 0.9188\n",
      "Set LR to 4.109423525312737e-05\n",
      "AUC: 0.9187688231468201\n",
      "AUC improved from 0.9121029376983643 to 0.9187688231468201\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 9.2483e-04 - auc: 0.9999\n",
      "Epoch 7/10\n",
      "409/409 [==============================] - 18s 43ms/step - loss: 0.0508 - auc: 0.9207\n",
      "Set LR to 2.8549663646838717e-05\n",
      "AUC: 0.920684278011322\n",
      "AUC improved from 0.9187688231468201 to 0.920684278011322\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 4.4248e-04 - auc: 1.0000\n",
      "Epoch 8/10\n",
      "409/409 [==============================] - 18s 43ms/step - loss: 0.0514 - auc: 0.9174\n",
      "Set LR to 1.859423525312737e-05\n",
      "AUC: 0.9173668026924133\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 2.3506e-04 - auc: 1.0000\n",
      "Epoch 9/10\n",
      "409/409 [==============================] - 18s 44ms/step - loss: 0.0621 - auc: 0.9187\n",
      "Set LR to 1.2202456766718093e-05\n",
      "AUC: 0.9186623692512512\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 1.7173e-04 - auc: 1.0000\n",
      "Epoch 10/10\n",
      "409/409 [==============================] - 18s 43ms/step - loss: 0.0605 - auc: 0.9151\n",
      "Set LR to 0.0001\n",
      "AUC: 0.9151432514190674\n",
      "715/715 [==============================] - 163s 227ms/step - loss: 1.0281e-04 - auc: 1.0000\n",
      "***********Fold 3*************\n",
      "Epoch 1/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.1026 - auc: 0.6118\n",
      "Set LR to 9.779754323328192e-05\n",
      "AUC: 0.611781120300293\n",
      "AUC improved from -inf to 0.611781120300293\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 0.0323 - auc: 0.8364\n",
      "Epoch 2/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0286 - auc: 0.9116\n",
      "Set LR to 9.140576474687264e-05\n",
      "AUC: 0.9115776419639587\n",
      "AUC improved from 0.611781120300293 to 0.9115776419639587\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 0.0208 - auc: 0.9313\n",
      "Epoch 3/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0293 - auc: 0.9109\n",
      "Set LR to 8.14503363531613e-05\n",
      "AUC: 0.9108785390853882\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 0.0116 - auc: 0.9804\n",
      "Epoch 4/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0362 - auc: 0.9149\n",
      "Set LR to 6.890576474687264e-05\n",
      "AUC: 0.9149488210678101\n",
      "AUC improved from 0.9115776419639587 to 0.9149488210678101\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 0.0056 - auc: 0.9959\n",
      "Epoch 5/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0365 - auc: 0.9235\n",
      "Set LR to 5.5e-05\n",
      "AUC: 0.92347651720047\n",
      "AUC improved from 0.9149488210678101 to 0.92347651720047\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 0.0023 - auc: 0.9995\n",
      "Epoch 6/10\n",
      "1041/1041 [==============================] - 18s 17ms/step - loss: 0.0533 - auc: 0.9233\n",
      "Set LR to 4.109423525312737e-05\n",
      "AUC: 0.9233129620552063\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 0.0011 - auc: 0.9999\n",
      "Epoch 7/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0528 - auc: 0.9224\n",
      "Set LR to 2.8549663646838717e-05\n",
      "AUC: 0.9224214553833008\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 4.0969e-04 - auc: 1.0000\n",
      "Epoch 8/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0552 - auc: 0.9226\n",
      "Set LR to 1.859423525312737e-05\n",
      "AUC: 0.9225924015045166\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 2.1409e-04 - auc: 1.0000\n",
      "Epoch 9/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0548 - auc: 0.9258\n",
      "Set LR to 1.2202456766718093e-05\n",
      "AUC: 0.9258046746253967\n",
      "AUC improved from 0.92347651720047 to 0.9258046746253967\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 1.2044e-04 - auc: 1.0000\n",
      "Epoch 10/10\n",
      "1041/1041 [==============================] - 18s 18ms/step - loss: 0.0595 - auc: 0.9245\n",
      "Set LR to 0.0001\n",
      "AUC: 0.9245122075080872\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 9.2286e-05 - auc: 1.0000\n",
      "***********Fold 4*************\n",
      "Epoch 1/10\n",
      "  2/715 [..............................] - ETA: 1:12 - loss: 0.0574 - auc: 0.7281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0780s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0693 - auc: 0.4398\n",
      "Set LR to 9.779754323328192e-05\n",
      "AUC: 0.43980199098587036\n",
      "AUC improved from -inf to 0.43980199098587036\n",
      "715/715 [==============================] - 164s 229ms/step - loss: 0.0334 - auc: 0.8281\n",
      "Epoch 2/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0221 - auc: 0.9207\n",
      "Set LR to 9.140576474687264e-05\n",
      "AUC: 0.9206753373146057\n",
      "AUC improved from 0.43980199098587036 to 0.9206753373146057\n",
      "715/715 [==============================] - 164s 230ms/step - loss: 0.0211 - auc: 0.9287\n",
      "Epoch 3/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0236 - auc: 0.9252\n",
      "Set LR to 8.14503363531613e-05\n",
      "AUC: 0.9252479076385498\n",
      "AUC improved from 0.9206753373146057 to 0.9252479076385498\n",
      "715/715 [==============================] - 165s 230ms/step - loss: 0.0115 - auc: 0.9808\n",
      "Epoch 4/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0306 - auc: 0.9224\n",
      "Set LR to 6.890576474687264e-05\n",
      "AUC: 0.9224317669868469\n",
      "715/715 [==============================] - 165s 231ms/step - loss: 0.0058 - auc: 0.9957\n",
      "Epoch 5/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0400 - auc: 0.9249\n",
      "Set LR to 5.5e-05\n",
      "AUC: 0.9249454140663147\n",
      "715/715 [==============================] - 163s 228ms/step - loss: 0.0025 - auc: 0.9992\n",
      "Epoch 6/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0412 - auc: 0.9228\n",
      "Set LR to 4.109423525312737e-05\n",
      "AUC: 0.9227926731109619\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 9.7890e-04 - auc: 0.9999\n",
      "Epoch 7/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0692 - auc: 0.9159\n",
      "Set LR to 2.8549663646838717e-05\n",
      "AUC: 0.9159407019615173\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 4.2821e-04 - auc: 1.0000\n",
      "Epoch 8/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0606 - auc: 0.9207\n",
      "Set LR to 1.859423525312737e-05\n",
      "AUC: 0.9207085967063904\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 2.6411e-04 - auc: 1.0000\n",
      "Epoch 9/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0632 - auc: 0.9223\n",
      "Set LR to 1.2202456766718093e-05\n",
      "AUC: 0.922309935092926\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 1.1856e-04 - auc: 1.0000\n",
      "Epoch 10/10\n",
      "1041/1041 [==============================] - 19s 18ms/step - loss: 0.0598 - auc: 0.9230\n",
      "Set LR to 0.0001\n",
      "AUC: 0.9229640960693359\n",
      "715/715 [==============================] - 163s 229ms/step - loss: 1.0055e-04 - auc: 1.0000\n",
      "[0.9243723750114441, 0.9098753333091736, 0.920684278011322, 0.9258046746253967, 0.9252479076385498]\n",
      "0.9211969137191772\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Training\n",
    "'''\n",
    "kf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=2020)\n",
    "fold = 0\n",
    "val_auc = []\n",
    "for train_idx, test_idx in kf.split(image_ids, targets):\n",
    "    print(f\"***********Fold {fold}*************\")\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = build_model(fold, prev_img_size)\n",
    "    \n",
    "    train_image_ids, train_targets = image_ids[train_idx], targets[train_idx]\n",
    "    test_image_ids, test_targets = image_ids[test_idx], targets[test_idx]\n",
    "    \n",
    "    train_gen = Datagen(train_image_ids, train_targets, BATCH_SIZE, TRAIN_IMAGE_PATH, None)\n",
    "    val_bs = 1\n",
    "    for i in range(32, 1, -1):\n",
    "        if len(test_image_ids) % i == 0:\n",
    "            val_bs = i\n",
    "            break\n",
    "    val_gen = Datagen(test_image_ids, test_targets, val_bs, TRAIN_IMAGE_PATH, test_aug, 'valid')\n",
    "    \n",
    "    callbacks = [Evaluate(fold, train_gen, val_gen, f'../data/model_checkpoint/{model_name}')]\n",
    "    \n",
    "    model.fit_generator(train_gen,\n",
    "                        steps_per_epoch=len(train_gen),\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "    val_auc.append(callbacks[0].best_score)\n",
    "    fold += 1\n",
    "    \n",
    "print(val_auc)\n",
    "print(np.mean(val_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baseline: 0.921"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
