{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from efficientnet.tfkeras import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers import Optimizer, Adam\n",
    "\n",
    "from tensorflow_addons.optimizers import SWA\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed():\n",
    "    random.seed(2021)\n",
    "    tf.random.set_seed(2020)\n",
    "    np.random.seed(2019)\n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HairAugmentation(DualTransform):\n",
    "    \"\"\"\n",
    "    Impose an image of a hair to the target image\n",
    "\n",
    "    Args:\n",
    "        hairs (int): maximum number of hairs to impose\n",
    "        hairs_folder (str): path to the folder with hairs images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hairs, hairs_data, always_apply=False, p=0.5):\n",
    "        super(HairAugmentation, self).__init__(always_apply, p)\n",
    "        self.hairs = hairs\n",
    "        self.hairs_data = hairs_data\n",
    "\n",
    "    def apply(self, image, n_hairs, **params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to draw hairs on.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Image with drawn hairs.\n",
    "        \"\"\"    \n",
    "        if not n_hairs:\n",
    "            return image\n",
    "        \n",
    "        height, width, _ = image.shape  # target image width and height\n",
    "        \n",
    "        for _ in range(n_hairs):\n",
    "            idx = np.random.randint(0, len(self.hairs_data))\n",
    "            hair = self.hairs_data[idx]\n",
    "            hair = cv2.flip(hair, np.random.choice([-1, 0, 1]))\n",
    "            hair = cv2.rotate(hair, np.random.choice([0, 1, 2]))\n",
    "\n",
    "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "            roi_ho = np.random.randint(0, image.shape[0] - hair.shape[0])\n",
    "            roi_wo = np.random.randint(0, image.shape[1] - hair.shape[1])\n",
    "            roi = image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
    "\n",
    "            # Creating a mask and inverse mask\n",
    "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "            # Now black-out the area of hair in ROI\n",
    "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "            # Take only region of hair from hair image.\n",
    "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
    "\n",
    "            # Put hair in ROI and modify the target image\n",
    "            dst = cv2.add(img_bg, hair_fg)\n",
    "\n",
    "            image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
    "                \n",
    "        return image\n",
    "    \n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        n_hairs = np.random.randint(0, self.hairs)\n",
    "        return {'n_hairs': n_hairs }\n",
    "    \n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "    \n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('hairs', 'hairs_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "prev_img_size = None\n",
    "BATCH_SIZE = 32\n",
    "SPLITS = 5\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "TRAIN_IMAGE_PATH = '../data/train_256'\n",
    "\n",
    "ORIGINAL_TRAIN_DF = pd.read_csv('../data/cleaned_train.csv')\n",
    "EXTERNAL_TRAIN_DF = pd.read_csv('../data/external_train.csv')\n",
    "\n",
    "model_name = 'seresnet18'\n",
    "PHI = 0\n",
    "initial_lr = 1e-4\n",
    "min_lr = 1e-5\n",
    "\n",
    "# Prepare hairs data for Hair Augmentation\n",
    "hairs_data = []\n",
    "for file in os.listdir('../data/hairs'):\n",
    "    img = cv2.imread(f'../data/hairs/{file}')\n",
    "    h, w, _ = img.shape\n",
    "    img = cv2.resize(img, (w // 4, h // 4), cv2.INTER_AREA)\n",
    "    hairs_data.append(img)\n",
    "\n",
    "train_aug = A.Compose([\n",
    "#                 HairAugmentation(hairs=5, hairs_data=hairs_data),\n",
    "                A.Flip(),\n",
    "                A.ShiftScaleRotate(),\n",
    "                A.RandomBrightnessContrast(),\n",
    "                A.Cutout(num_holes=1, max_h_size=IMG_SIZE // 2, max_w_size=IMG_SIZE // 2)\n",
    "            ])\n",
    "test_aug = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Data Generator\n",
    "'''\n",
    "class Datagen(Sequence):\n",
    "    def __init__(self, list_ids, targets, batch_size, image_dir, generator=None, mode='training'):\n",
    "        self.list_ids = list_ids\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dir = image_dir\n",
    "        self.generator = generator\n",
    "        self.indices = np.arange(self.list_ids.shape[0])\n",
    "        self.mode = mode\n",
    "        \n",
    "    def preprocessing_image(self, image):\n",
    "        image = image.astype('float32') / 255.\n",
    "        return image\n",
    "        \n",
    "    def read_image(self, image_id):\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR) \n",
    "        return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_ids) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index + 1)*self.batch_size]\n",
    "        image_ids = self.list_ids[indices]\n",
    "        y = self.targets[indices]\n",
    "        X = np.empty((len(image_ids), IMG_SIZE, IMG_SIZE, 3), dtype='float32')\n",
    "        for i in range(len(image_ids)):\n",
    "            image = self.read_image(image_ids[i])\n",
    "            if self.generator is not None:\n",
    "                image = self.generator(image=image)['image']\n",
    "            image = self.preprocessing_image(image)\n",
    "            X[i] = image\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode == 'training':\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Model\n",
    "'''\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.75):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def build_model(fold=None, prev_img_size=None):\n",
    "    M = 0\n",
    "    EFFNET_MODEL = [EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3]\n",
    "    if 'efficientnet' in model_name:\n",
    "        M = EFFNET_MODEL[PHI]\n",
    "    else:\n",
    "        M, _ = Classifiers.get(model_name)\n",
    "    base_model = M(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "    model = Model(inputs=[base_model.input], outputs=[out])\n",
    "    if prev_img_size is not None:\n",
    "        model.load_weights(f'../data/model_checkpoint/{model_name}/{model_name}_{prev_img_size}_fold_{fold}.h5')\n",
    "    opt = keras.optimizers.Adam(lr=initial_lr)\n",
    "    opt = SWA(opt)\n",
    "    opt = runai.ga.tfkeras.optimizers.Optimizer(opt, steps=4)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=focal_loss(),\n",
    "                  metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Callback\n",
    "'''\n",
    "def scheduler(epoch):\n",
    "    return min_lr + (initial_lr - min_lr) * (1 + np.cos(np.pi * (epoch % EPOCHS) / EPOCHS)) / 2\n",
    "\n",
    "class Evaluate(keras.callbacks.Callback):\n",
    "    def __init__(self, fold, train_gen, valid_gen, model_checkpoint):\n",
    "        self.fold = fold\n",
    "        self.train_gen = train_gen\n",
    "        self.valid_gen = valid_gen\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.best_score = float('-inf')\n",
    "    \n",
    "    def compute_auc(self, y_true, y_pred):\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.train_gen.on_epoch_end()\n",
    "        _, auc = self.model.evaluate_generator(self.valid_gen, verbose=1)\n",
    "        new_lr = scheduler(epoch + 1)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "        print(\"Set LR to {}\".format(new_lr))\n",
    "        print(\"AUC: {}\".format(auc))\n",
    "        if auc > self.best_score:\n",
    "            print(f\"AUC improved from {self.best_score} to {auc}\")\n",
    "            self.best_score = auc\n",
    "            self.model.save_weights(f'{self.model_checkpoint}/{model_name}_{IMG_SIZE}_fold_{self.fold}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_image_ids = np.asarray(EXTERNAL_TRAIN_DF['image_name'])\n",
    "external_targets = np.asarray(EXTERNAL_TRAIN_DF['target'], dtype='float32')\n",
    "\n",
    "image_ids = np.asarray(ORIGINAL_TRAIN_DF['image_name'])\n",
    "targets = np.asarray(ORIGINAL_TRAIN_DF['target'], dtype='float32')\n",
    "\n",
    "image_ids = np.concatenate([image_ids, external_image_ids])\n",
    "targets = np.concatenate([targets, external_targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Fold 0*************\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3c06d104e464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_img_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_image_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c88019976320>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(fold, prev_img_size)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../data/model_checkpoint/{model_name}/{model_name}_{prev_img_size}_fold_{fold}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;31m#     opt = keras.optimizers.Adam(lr=initial_lr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdamAccumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSWA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c88019976320>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lr, beta_1, beta_2, epsilon, decay, amsgrad, accum_iters, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maccum_iters\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accum_iters must be >= 1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdamAccumulate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Training\n",
    "'''\n",
    "kf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=2020)\n",
    "fold = 0\n",
    "val_auc = []\n",
    "for train_idx, test_idx in kf.split(image_ids, targets):\n",
    "    print(f\"***********Fold {fold}*************\")\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = build_model(fold, prev_img_size)\n",
    "    \n",
    "    train_image_ids, train_targets = image_ids[train_idx], targets[train_idx]\n",
    "    test_image_ids, test_targets = image_ids[test_idx], targets[test_idx]\n",
    "    \n",
    "    train_gen = Datagen(train_image_ids, train_targets, BATCH_SIZE, TRAIN_IMAGE_PATH, train_aug)\n",
    "    val_bs = 1\n",
    "    for i in range(32, 1, -1):\n",
    "        if len(test_image_ids) % i == 0:\n",
    "            val_bs = i\n",
    "            break\n",
    "    val_gen = Datagen(test_image_ids, test_targets, val_bs, TRAIN_IMAGE_PATH, test_aug, 'valid')\n",
    "    \n",
    "    callbacks = [Evaluate(fold, train_gen, val_gen, f'../data/model_checkpoint/{model_name}')]\n",
    "    \n",
    "    model.fit_generator(train_gen,\n",
    "                        steps_per_epoch=len(train_gen),\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "    val_auc.append(callbacks[0].best_score)\n",
    "    fold += 1\n",
    "    \n",
    "print(val_auc)\n",
    "print(np.mean(val_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- focal_loss_cv = 0.953\n",
    "- add blur cv = 0.951\n",
    "- flip, ssr, color = 0.952\n",
    "- add cutout = 0.9525\n",
    "\n",
    "- efficientnetb0 256 = 0.96022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
